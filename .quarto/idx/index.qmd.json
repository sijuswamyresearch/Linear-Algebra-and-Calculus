{"title":"Introduction to Linear ALgebra and Calculus","markdown":{"yaml":{"title":"Introduction to Linear ALgebra and Calculus","format":"html","jupyter":"python3"},"headingText":"Introduction to Linear ALgebra and Calculus","containsRefs":false,"markdown":"\n\n\n## Why Are You Here?\n\nWelcome. You are here because you want to build the future. You want to design the next generation of intelligent devices, write the code that powers artificial intelligence, and create the communication systems that connect the world. My goal in this course is not to just teach you mathematics, but to give you the fundamental language and toolkit you will use to achieve those goals.\n\nOver the next five years, the fields of electronics and computer science will be dominated by machine learning, robotics, next-generation wireless communication (5G and 6G), and incredibly complex integrated circuits. The code you'll write, the systems you'll design—they all speak a language. That language is a beautiful combination of linear algebra and calculus.\n\nThis course is your Rosetta Stone. We will move beyond memorizing formulas and instead focus on three questions for every topic:\n\n1.  **What is the core idea?** (The Intuition)\n2.  **Why does it work?** (The Theory)\n3.  **What can I build with it?** (The Application)\n\nLet's look at the journey ahead and connect it directly to the technologies you will be creating.\n\n## The Syllabus: A 4-Year Technology Roadmap\n\n### Module I: Systems of Linear Equations — The Language of Problems\n\n*   **The Math:** You'll learn to solve systems of equations, `Ax = b`. We'll explore this through the \"Row Picture\" (intersecting planes) and the \"Column Picture\" (combining vectors).\n*   **The 4-Year Horizon:**\n    *   **VLSI Chip Design:** A modern processor has billions of transistors. Analyzing the voltages and currents across this massive network is a linear algebra problem on an unimaginable scale. The methods we start with here are the foundation for the software that designs and verifies the chips in your phone and computer.\n    *   **Network Analysis:** How does Google balance traffic across its millions of servers? How does data flow through the internet? These are gigantic systems of linear equations, where the variables are data rates and server loads.\n    *   **Machine Learning Models:** Training a simple model can involve solving for thousands of parameters simultaneously. This is `Ax = b` in disguise.\n\n### Module II: Eigenvalues & Eigenvectors — The DNA of a System\n\n*   **The Math:** We will find the \"special\" vectors of a matrix, the ones that don't change direction when transformed (`Ax = λx`). These are the eigenvectors, and they reveal the deepest properties of a system.\n*   **The 5-Year Horizon:**\n    *   **Principal Component Analysis (PCA):** How does your phone recognize your face so quickly? It uses PCA to reduce a high-resolution image to its most important features—its \"principal components.\" These are, quite literally, the eigenvectors of the data's covariance matrix. This is essential for data compression and machine learning.\n    *   **Quantum Computing:** The state of a qubit is a vector. The possible measurement outcomes are the eigenvalues of its operator matrix. The fundamental principles of quantum mechanics, which will power the next computing revolution, are expressed in the language of eigenvalues.\n    *   **Robotics and Control Systems:** When you design a robot arm or a drone, you need it to be stable. The eigenvalues of its control system matrix tell you if it will shake itself apart or smoothly return to equilibrium. A positive eigenvalue could mean disaster!\n\n### Modules III & IV: Multivariable Calculus — The Landscape of Optimization\n\n*   **The Math:** We'll explore functions of multiple variables, finding their peaks and valleys using partial derivatives (the gradient `∇f`) and calculating volumes under surfaces with multiple integrals (`∬`).\n*   **The 4-Year Horizon:**\n    *   **Gradient Descent (The Engine of AI):** This is the single most important application of calculus for you. How does a neural network learn? It calculates an \"error landscape\" (a high-dimensional surface) and uses the gradient to find the direction to \"descend\" towards the lowest error. Every time you hear about a model being \"trained,\" you are hearing about gradient descent in action. This is the engine that drives the entire AI revolution.\n    *   **Computer Graphics & AR/VR:** How does a GPU render realistic lighting and shadows on a 3D object in a game? It calculates surface normals (using gradients) and performs integrals over surfaces to determine how light reflects. This is multivariable calculus happening in real-time.\n    *   **Robotics Path Planning:** A robot navigating a complex terrain uses calculus to find the optimal, most energy-efficient path—essentially finding a \"valley\" in a \"cost landscape.\"\n\n### Module V: Series Representation — The Art of Approximation\n\n*   **The Math:** We will learn to approximate complex functions with simpler building blocks: polynomials (Taylor Series) and sine/cosine waves (Fourier Series).\n*   **The 4-Year Horizon:**\n    *   **Signal Processing (5G, Wi-Fi, Audio):** Your phone receives a messy, complex radio wave. The **Fourier Transform** breaks this signal down into its constituent frequencies, separating the data from the noise. This is the absolute heart of all modern digital communications and audio/video compression (like MP3 and JPEG). The future of wireless technology is built on Fourier analysis.\n    *   **Embedded Systems & IoT:** A tiny sensor in an IoT device doesn't have the processing power to calculate `sin(x)` precisely. Instead, it uses the first few terms of a Taylor series—a simple polynomial—to get an answer that is \"good enough\" while saving precious battery life and clock cycles.\n\n## How We'll Learn: Building Computational Intuition\n\nTo make these connections real, we won't just use pen and paper. We will use Python, the language of modern scientific computing and AI. You will learn to use libraries like NumPy, Matplotlib, and Plotly to see these concepts in action.\n\nFor example, when we say that solving `Ax=b` is about finding the right combination of column vectors, what does that *look* like? It looks like this:\n\n```{python}\n#| label: fig-computational-intuition\n#| fig-cap: \"The Column Picture: Using Python to see that 2 of the blue vector plus 3 of the green vector builds the red target vector.\"\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# The column vectors from our system\nv1 = np.array([2, 1])     # First column\nv2 = np.array([-1, 1])    # Second column\n\n# The target vector on the right-hand side\nb = np.array([1, 5])      # Should equal 2*v1 + 3*v2\n\n# The solution we will learn to find is x=2, y=3\nx, y = 2, 3\n\n# --- Visualization ---\nplt.figure(figsize=(8, 8))\nax = plt.gca()\n\n# Plot the basis vectors\nax.quiver(0, 0, v1[0], v1[1], angles='xy', scale_units='xy', scale=1,\n          color='blue', label=r'Column 1: $v_1$')\nax.quiver(0, 0, v2[0], v2[1], angles='xy', scale_units='xy', scale=1,\n          color='green', label=r'Column 2: $v_2$')\n\n# Plot the linear combination step by step\nax.quiver(0, 0, (x*v1)[0], (x*v1)[1], angles='xy', scale_units='xy', scale=1,\n          color='lightblue', alpha=0.8, label=r'$2v_1$')\nax.quiver((x*v1)[0], (x*v1)[1], (y*v2)[0], (y*v2)[1], angles='xy', scale_units='xy', scale=1,\n          color='lightgreen', alpha=0.8, label=r'$3v_2$')\n\n# Plot the target vector b\nax.quiver(0, 0, b[0], b[1], angles='xy', scale_units='xy', scale=1,\n          color='red', label=r'Target Vector $b$')\n\n# Formatting\nax.set_xlim(-2, 6)\nax.set_ylim(-1, 7)\nax.grid(True)\nax.set_title(\"Visualizing the Solution to Ax=b\")\nax.legend()\nplt.show()\n\n```\n\nBy the end of this course, you won't just be able to solve these problems. You will have a deep, visual, and computational intuition for them. You will see a problem in your own field and recognize the mathematical tools needed to solve it.\n\nThis course is your first and most important step towards becoming a true architect of future technology. Let's get started.","srcMarkdownNoYaml":"\n\n# Introduction to Linear ALgebra and Calculus\n\n## Why Are You Here?\n\nWelcome. You are here because you want to build the future. You want to design the next generation of intelligent devices, write the code that powers artificial intelligence, and create the communication systems that connect the world. My goal in this course is not to just teach you mathematics, but to give you the fundamental language and toolkit you will use to achieve those goals.\n\nOver the next five years, the fields of electronics and computer science will be dominated by machine learning, robotics, next-generation wireless communication (5G and 6G), and incredibly complex integrated circuits. The code you'll write, the systems you'll design—they all speak a language. That language is a beautiful combination of linear algebra and calculus.\n\nThis course is your Rosetta Stone. We will move beyond memorizing formulas and instead focus on three questions for every topic:\n\n1.  **What is the core idea?** (The Intuition)\n2.  **Why does it work?** (The Theory)\n3.  **What can I build with it?** (The Application)\n\nLet's look at the journey ahead and connect it directly to the technologies you will be creating.\n\n## The Syllabus: A 4-Year Technology Roadmap\n\n### Module I: Systems of Linear Equations — The Language of Problems\n\n*   **The Math:** You'll learn to solve systems of equations, `Ax = b`. We'll explore this through the \"Row Picture\" (intersecting planes) and the \"Column Picture\" (combining vectors).\n*   **The 4-Year Horizon:**\n    *   **VLSI Chip Design:** A modern processor has billions of transistors. Analyzing the voltages and currents across this massive network is a linear algebra problem on an unimaginable scale. The methods we start with here are the foundation for the software that designs and verifies the chips in your phone and computer.\n    *   **Network Analysis:** How does Google balance traffic across its millions of servers? How does data flow through the internet? These are gigantic systems of linear equations, where the variables are data rates and server loads.\n    *   **Machine Learning Models:** Training a simple model can involve solving for thousands of parameters simultaneously. This is `Ax = b` in disguise.\n\n### Module II: Eigenvalues & Eigenvectors — The DNA of a System\n\n*   **The Math:** We will find the \"special\" vectors of a matrix, the ones that don't change direction when transformed (`Ax = λx`). These are the eigenvectors, and they reveal the deepest properties of a system.\n*   **The 5-Year Horizon:**\n    *   **Principal Component Analysis (PCA):** How does your phone recognize your face so quickly? It uses PCA to reduce a high-resolution image to its most important features—its \"principal components.\" These are, quite literally, the eigenvectors of the data's covariance matrix. This is essential for data compression and machine learning.\n    *   **Quantum Computing:** The state of a qubit is a vector. The possible measurement outcomes are the eigenvalues of its operator matrix. The fundamental principles of quantum mechanics, which will power the next computing revolution, are expressed in the language of eigenvalues.\n    *   **Robotics and Control Systems:** When you design a robot arm or a drone, you need it to be stable. The eigenvalues of its control system matrix tell you if it will shake itself apart or smoothly return to equilibrium. A positive eigenvalue could mean disaster!\n\n### Modules III & IV: Multivariable Calculus — The Landscape of Optimization\n\n*   **The Math:** We'll explore functions of multiple variables, finding their peaks and valleys using partial derivatives (the gradient `∇f`) and calculating volumes under surfaces with multiple integrals (`∬`).\n*   **The 4-Year Horizon:**\n    *   **Gradient Descent (The Engine of AI):** This is the single most important application of calculus for you. How does a neural network learn? It calculates an \"error landscape\" (a high-dimensional surface) and uses the gradient to find the direction to \"descend\" towards the lowest error. Every time you hear about a model being \"trained,\" you are hearing about gradient descent in action. This is the engine that drives the entire AI revolution.\n    *   **Computer Graphics & AR/VR:** How does a GPU render realistic lighting and shadows on a 3D object in a game? It calculates surface normals (using gradients) and performs integrals over surfaces to determine how light reflects. This is multivariable calculus happening in real-time.\n    *   **Robotics Path Planning:** A robot navigating a complex terrain uses calculus to find the optimal, most energy-efficient path—essentially finding a \"valley\" in a \"cost landscape.\"\n\n### Module V: Series Representation — The Art of Approximation\n\n*   **The Math:** We will learn to approximate complex functions with simpler building blocks: polynomials (Taylor Series) and sine/cosine waves (Fourier Series).\n*   **The 4-Year Horizon:**\n    *   **Signal Processing (5G, Wi-Fi, Audio):** Your phone receives a messy, complex radio wave. The **Fourier Transform** breaks this signal down into its constituent frequencies, separating the data from the noise. This is the absolute heart of all modern digital communications and audio/video compression (like MP3 and JPEG). The future of wireless technology is built on Fourier analysis.\n    *   **Embedded Systems & IoT:** A tiny sensor in an IoT device doesn't have the processing power to calculate `sin(x)` precisely. Instead, it uses the first few terms of a Taylor series—a simple polynomial—to get an answer that is \"good enough\" while saving precious battery life and clock cycles.\n\n## How We'll Learn: Building Computational Intuition\n\nTo make these connections real, we won't just use pen and paper. We will use Python, the language of modern scientific computing and AI. You will learn to use libraries like NumPy, Matplotlib, and Plotly to see these concepts in action.\n\nFor example, when we say that solving `Ax=b` is about finding the right combination of column vectors, what does that *look* like? It looks like this:\n\n```{python}\n#| label: fig-computational-intuition\n#| fig-cap: \"The Column Picture: Using Python to see that 2 of the blue vector plus 3 of the green vector builds the red target vector.\"\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# The column vectors from our system\nv1 = np.array([2, 1])     # First column\nv2 = np.array([-1, 1])    # Second column\n\n# The target vector on the right-hand side\nb = np.array([1, 5])      # Should equal 2*v1 + 3*v2\n\n# The solution we will learn to find is x=2, y=3\nx, y = 2, 3\n\n# --- Visualization ---\nplt.figure(figsize=(8, 8))\nax = plt.gca()\n\n# Plot the basis vectors\nax.quiver(0, 0, v1[0], v1[1], angles='xy', scale_units='xy', scale=1,\n          color='blue', label=r'Column 1: $v_1$')\nax.quiver(0, 0, v2[0], v2[1], angles='xy', scale_units='xy', scale=1,\n          color='green', label=r'Column 2: $v_2$')\n\n# Plot the linear combination step by step\nax.quiver(0, 0, (x*v1)[0], (x*v1)[1], angles='xy', scale_units='xy', scale=1,\n          color='lightblue', alpha=0.8, label=r'$2v_1$')\nax.quiver((x*v1)[0], (x*v1)[1], (y*v2)[0], (y*v2)[1], angles='xy', scale_units='xy', scale=1,\n          color='lightgreen', alpha=0.8, label=r'$3v_2$')\n\n# Plot the target vector b\nax.quiver(0, 0, b[0], b[1], angles='xy', scale_units='xy', scale=1,\n          color='red', label=r'Target Vector $b$')\n\n# Formatting\nax.set_xlim(-2, 6)\nax.set_ylim(-1, 7)\nax.grid(True)\nax.set_title(\"Visualizing the Solution to Ax=b\")\nax.legend()\nplt.show()\n\n```\n\nBy the end of this course, you won't just be able to solve these problems. You will have a deep, visual, and computational intuition for them. You will see a problem in your own field and recognize the mathematical tools needed to solve it.\n\nThis course is your first and most important step towards becoming a true architect of future technology. Let's get started."},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":true,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.7.31","bibliography":["references.bib"],"jupyter":"python3","theme":"cosmo","fig-cap-location":"bottom","mathjax":true,"title":"Introduction to Linear ALgebra and Calculus"},"extensions":{"book":{"multiFile":true}}},"pdf":{"identifier":{"display-name":"PDF","target-format":"pdf","base-format":"pdf"},"execute":{"fig-width":5.5,"fig-height":3.5,"fig-format":"pdf","fig-dpi":300,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"pdf","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":true,"merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"pdf-engine":"xelatex","standalone":true,"variables":{"graphics":true,"tables":true},"default-image-extension":"pdf","to":"pdf","include-in-header":[{"text":"\\usepackage{amsmath}\n\\usepackage{amssymb}\n"}],"output-file":"index.pdf"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"block-headings":true,"bibliography":["references.bib"],"jupyter":"python3","title":"Introduction to Linear ALgebra and Calculus"},"extensions":{"book":{"selfContainedOutput":true}}}},"projectFormats":["html","pdf"]}